# 答辩稿
各位老师好，我本次毕业设计的题目是Linux服务器监控告警系统的设计与实现。  
接下来我将按照选题意义，技术选型，设计实现，系统测试，总结展望的顺序介绍我在毕业设计期间所完成的主要工作。  

## 选题意义
在云服务领域中，Linux服务器始终占据着市场的主导地位，监控告警系统则是Linux服务器运维管理中最为重要的一环。  
调查了国内外监控告警系统的现状之后，我发现其主要分为两类：一类是云服务商针对自身服务提供的定制产品，另一类则是由开源社区发起的活跃项目。两类监控告警系统均有着各自的不足，要想与企业已有业务紧密结合，在关键位置进行深度定制的话，一套自主开发的监控告警系统是必不可少的。  

## 技术选型
这边是我的技术选型。  
技术选型在毕业设计的准备阶段极为重要，没有任何一门技术可以完美地适用于所有开发场景，实际的软件开发过程中也往往要根据具体需求选取出最为合适的解决方案。  
* Golang原生支持并发、方便交叉编译、可混合调用C语言代码等特点使得它成为了采集监控数据的最佳选择。
* Node.js的事件驱动和非阻塞异步I/O能够赋予监控告警系统承载海量并发连接的能力。
* TimescaleDB时序数据库为监控数据的压缩存储、聚合查询等提供了性能保证。
* 成熟的React前端框架不仅为管理员提供了友好的交互体验，也为历史监控数据提供了灵活的展示方式。
* Nginx负责为整个系统提供负载均衡和故障时的冗余切换。
* 最后开发及部署过程中用到的Docker大大简化了环境配置过程，使得我有更多的精力放在其他方面。

## 设计实现
### 架构设计
然后是系统的整体架构。
系统整体分为监控采集模块，数据存储与处理模块，还有可视化模块三个部分，监控采集模块将采集到的监控数据上报到数据存储与处理模块，数据存储与处理模块校验后将数据存入数据库，同时对新增的数据进行阈值检查，触发告警后根据设定好的推送渠道发送告警信息，管理员与可视化模块进行直接交互，可在控制台设置监控规则和推送目标，也可指定主机查看历史监控数据分析变化趋势，可视化模块所调用的接口均由数据存储与处理模块提供。  

### 监控采集模块
接下来是具体的模块实现。  
在监控采集模块的实现过程中，我先参考了国内阿里云提供的云监控服务，确定了基础监控指标，然后在其之上进行了适当的扩展，如编写PAM模块实现SSH登录统计，利用inotify API进行文件操作监控等。  
然后我学习了Linux的系统调用及伪文件系统相关知识，阅读常用运维工具的开源代码，如top，free，lscpu，df，htop等命令，确定监控指标具体计算方式，尽量让计算出的数据与其它运维工具保持一致，符合运维人员直觉。  
对比了HTTP与WebSocket，根据监控数据持续上报的特点选择了WebSocket长连接的方式进行数据传输，统一了监控数据封装格式，方便数据存储与处理模块进行整合处理。  
最后还为监控采集模块设计了插件机制，为自定义监控指标预留接口，方便后期灵活扩展，前面提到的SSH登录统计和文件操作监控就是以插件形式运行在被监控服务器上的。

除此之外还利用Golang的并发编程对监控指标并行采集，并对一些细节进行了详细的测试对比，提高了监控采集模块的性能。如处理伪文件系统时要用到的文件读取，我搜集了Golang最常用的一些文件读取方式，并对其性能进行了测试，最终选择了最为高效的第二种组合。

### 数据存储与处理模块
接下来是数据存储与处理模块的实现。我在WebSocket基础上实现消息确认机制，监控采集模块运行期间会持续利用该机制检测网络状态，避免网络波动造成的监控数据丢失。  
然后抽象出了一个规则组结构，用来批量管理主机监控及推送渠道，监控规则或推送渠道的修改都是实时生效的。  
监控采集模块采集到的数据量是十分庞大的，因此在对历史监控数据查询的时候需要对数据点进行聚合，保证变化趋势的前提下减少数据点个数，降低网络带宽占用及前端图表的展示压力。  
最后数据查询方面还需要合理设置索引，结合数据表具体结构对相应SQL语句进行优化，加快历史监控数据查询速度。例如挂载点的查询，之前是利用group by找到指定主机所有挂载点之后利用时序数据库的last函数找到最新统计数据，随着数据量的增多速度明显下降，运行三周后单次查询甚至达到了1.5s，考虑到单台主机每次提交的所有挂载点具有相同的时间戳，改为找到指定主机的最新一次时间戳，再依据时间戳去取最新统计数据，查询结果可以在10ms内返回。  
这是官方的一个数据库写入速度对比，在8核16G的云服务器上插入了10亿行数据，可以看到该时序数据库的性能是极为优秀的。  
这边是自己所做的一个数据量测试，主机采集间隔10s的话，单主机单监控项每天新增8640条，这里的68万条数据相当于单台主机80天的数据量，只占用了1G多一点的硬盘空间，完全可以接受。  

### 可视化模块
最后是可视化模块的实现。  
采用Material Design提供的栅格布局，主页面布局自适应，保证页面元素视觉一致性。  
与后端模块完全分离，明确划分各模块功能职责，方便单独对可视化模块进行迭代更新。  
在原有图表库的基础图表上进行二次定制，优化数据点密集情况下的数据详情提示。  
Webpack前端编译优化，多页面结构配合chunk切割复用，优化浏览器端页面加载体验。  

## 测试部署
这边是我进行的实际线上部署，也是成果验收视频中演示出的整个系统部署结构，在视频中已经进行了监控告警，负载均衡，冗余切换的测试，之后为了给系统性能提供准确的数据支持，我又进行了数据采集测试，逐步减少采集间隔，测试监控采集模块和数据存储与处理模块的资源占用。表格中CPU使用率是相对于单核来说的，实际部署过程中单台主机可以部署多个数据存储与处理模块。监控间隔5ms时相当于单台主机单监控项每秒200条数据，实际上有多个监控项并行采集，每秒千条数据插入是完全没问题的。

## 总结展望
### 总结
本系统利用Golang原生的并发支持使得数据采集模块能够提供极细粒度下的监控数据，借助Node.js的事件驱动和非阻塞异步I/O赋予了数据存储模块对于海量并发连接的承载能力，时序数据库为数据的压缩存储、聚合查询等提供了性能保证，成熟的React前端框架为历史数据提供了友好的展示方式。最终合理的模块设计配合Nginx负载均衡使得完整的监控告警系统拥有了较强的横向扩展能力和冗余切换能力，完全具备应用于线上环境的潜力。

### 展望
由于开发时间受限，监控告警系统中还存在许多可以进一步完善的地方，如监控采集模块还可以针对各类数据库的运行数据提供状态监控插件；数据存储与处理模块可以将消息发送功能使用专门的消息队列进行解耦，方便增加失败重发，消息优先级一类的高级消息特性；前端可视化模块增加实时数据功能，自动从后端请求最新数据并保持动态更新；部署过程中自定义一个调度中心代替Nginx，监控采集模块配置由调度中心动态生成，根据实际网络情况分配最优数据上报路径等。如果有充足的时间进行改进，以上的这些遗憾都将被补全，系统设计阶段打下的良好基础为功能扩展留下了无限的可能。

好的，我的报告到此结束，谢谢各位老师的聆听，接下来恳请各位老师进行批评指正。

## 附：PPT 颜色选择
* 东大蓝 2b458c 43,69,140  
  <span style='color:#2b458c;background-color: #2b458c'>颜色测试</span>
* 强调黄 ff683a 255,104,58  
  <span style='color:#ff683a;background-color: #ff683a'>颜色测试</span>
* 字体灰 434343 67,67,67  
  <span style='color:#434343;background-color: #434343'>颜色测试</span>
