# Linux服务器监控告警系统的设计与实现 <!-- omit in toc -->
- [1. 绪论](#1-绪论)
  - [1.1 课题研究背景](#11-课题研究背景)
  - [1.2 课题研究意义](#12-课题研究意义)
  - [1.3 国内外现状](#13-国内外现状)
  - [1.4 论文研究内容](#14-论文研究内容)
  - [1.5 论文的组织结构](#15-论文的组织结构)
- [2. 关键技术介绍](#2-关键技术介绍)
  - [2.1 Golang](#21-golang)
  - [2.2 Node.js](#22-nodejs)
  - [2.3 Express](#23-express)
  - [2.4 React](#24-react)
  - [2.5 TimescaleDB](#25-timescaledb)
  - [2.6 本章小结](#26-本章小结)
- [3. 需求分析](#3-需求分析)
  - [3.1 系统概述](#31-系统概述)
  - [3.2 功能性需求分析](#32-功能性需求分析)
    - [3.2.1 数据采集](#321-数据采集)
    - [3.2.2 数据存储](#322-数据存储)
    - [3.2.3 监控报警](#323-监控报警)
    - [3.2.4 可视化](#324-可视化)
  - [3.3 非功能性需求分析](#33-非功能性需求分析)
    - [3.3.1 可行性分析](#331-可行性分析)
    - [3.3.2 性能效率分析](#332-性能效率分析)
    - [3.3.3 安全性分析](#333-安全性分析)
  - [3.4 本章小结](#34-本章小结)
- [4. 系统设计](#4-系统设计)
  - [4.1 设计目标](#41-设计目标)
  - [4.2 系统总体功能架构](#42-系统总体功能架构)
  - [4.3 系统技术实现架构](#43-系统技术实现架构)
  - [4.4 数据存储及使用](#44-数据存储及使用)
  - [4.5 本章小结](#45-本章小结)
- [5. 系统实现](#5-系统实现)
  - [5.1 数据采集模块](#51-数据采集模块)
  - [5.2 数据存储模块](#52-数据存储模块)
  - [5.3 前端可视化模块](#53-前端可视化模块)
  - [5.4 本章小结](#54-本章小结)
- [6. 系统测试](#6-系统测试)
- [7. 总结](#7-总结)
- [致谢](#致谢)

## 1. 绪论

### 1.1 课题研究背景
阐述选题的理由。

### 1.2 课题研究意义

### 1.3 国内外现状
对本课题现有的研究进展情况的简要介绍。

### 1.4 论文研究内容
本文所要解决的问题，采用的手段、方法和步骤，所需要的条件，预期成果。

### 1.5 论文的组织结构
本毕业设计的主要目的在于实现一套完整的Linux服务器监控告警系统，为Linux服务器的故障检测报警和性能瓶颈分析提供有力依据，提高企业内运维人员的工作效率。本论文各章节结构安排如下：  
第1章，绪论。介绍Linux服务器监控告警系统的研究背景与意义，分析国内外研究现状及发展趋势，最后安排论文的章节组织结构。  
第2章，关键技术。结合监控告警系统的技术选型过程，简述最终所选关键技术的主要优势以及选择的原因，为后文的设计与实现提供充足的理论基础。  
第3章，需求分析。通过用例的方式对高压发生器的控制软件进行需求分析，包括功能性需求分析和非功能性需求分析，进而得出高压发生器的用例模型。  

第4章，系统设计。进行软件及架构设计，对软件进行分层和模块划分。将软件分为硬件接口层、驱动程序层和应用程序层；将软件划分为硬件接口模块、控制模块、算法模块和数据模块。  
第5章，系统实现。实现了高压控制软件，给出硬件接口层模块、驱动程序层各驱动程序、应用层各模块的具体实现。  
第6章，系统测试。对高压基本功能编写测试用例，进行测试，得到相关波形。  
第7章，总结与展望。对工作做了简要的总结，并对后续工作提出了设想。  

## 2. 关键技术介绍

### 2.1 Golang
Golang是Google在2009年正式推出的一门编译型编程语言，其主要特点包括静态类型，原生支持并发，方便交叉编译，可混合调用C语言代码等，正是这些特点促使它成为了编写监控数据采集端的最佳选择。  
为了采集Linux系统的各项指标，首先想到的应该是使用C语言编写监控程序，方便直接利用Linux内核提供的系统调用读取各项系统信息，例如procps工具包中常用的free，ps，top等命令就全由C语言编写而成。但监控程序除了负责数据采集之外，还要对数据进行预处理，并将封装好的数据包发送到存储端，然而偏底层的特点使得C语言在数据封装和网络通信上具有一定的劣势，缺少包管理也让引入第三方依赖的成本较为高昂。相比之下，Golang丰富的标准库中提供了诸如net/http，encoding/json，crypto等常用的库，这使得Golang的数据封装和网络通信变得极为方便，而C语言所擅长的数据采集部分，Google官方也提供了golang.org/x/sys库封装好了常用的操作系统底层调用，因此在当前的使用场景下，Golang十分适合替代C语言担任监控数据采集端的角色。  
除了C语言，其他常用的编程语言还有C++，Java，Python等。C++对比C语言的主要优势是面向对象和标准模板库，但在当前的场景下其优势并不能发挥出来，和Golang比较时有着和C语言相同的缺点，因此不适合用来编写数据采集端。Java和Python相同，都需要提前配置额外的运行环境，Java需要JRE，Python需要解释器，作为Linux系统的监控数据采集端，应当尽可能地减少外部依赖，不能影响到被监控系统本身的生产环境，Golang作为编译型语言在这一点上同样占有优势。  
除此之外，Golang原生支持并发的特点使得各项监控数据很容易就可以做到并行采集，采集到的数据后续的封装和发送也可以与采集过程并行处理，这使得采集端拥有了提供极细粒度监控数据的能力。Golang方便交叉编译的特点体现在改变编译时的GOARCH环境变量就可以得到不同架构下的可执行程序，例如386，amd64，arm，arm64，mips等，可以轻松提供多个版本的监控端。

### 2.2 Node.js
Node.js是一个基于Google V8引擎的服务端JavaScript运行环境，主要特点是事件驱动和非阻塞异步I/O。JavaScript最初是运行在浏览器中的，V8引擎就是Google为其浏览器Chrome所设计的开源JavaScript引擎，但V8引擎并不局限于在浏览器中运行，它还提供了“嵌入”的功能，开发者可以在自己的程序中嵌入该引擎。于是在提供了一系列的文件系统I/O，网络通信，二进制数据流，加密算法等API接口之后，JavaScript就可以借助V8引擎运行在服务端。  
传统的服务端开发语言如PHP，Java等，在处理并发的连接时，通常会启动新的线程，每个线程对应一个连接，而Node.js打破了这一常规，通过事件驱动和非阻塞异步I/O，Node.js可以在单个线程中处理大量并发连接，减小了线程上下文切换的开销，有效地提升了对于大量并发连接的承载能力。生产环境下为了充分发挥多核CPU的优势，往往会启动多个服务进程或者利用Node.js本身的Cluster模块启动多个worker。  
考虑到数据采集端与存储端之间准备通过WebSocket长连接的方式进行通信，存储端的主要任务是转发监控数据到数据库和从数据库查询已有的监控数据，不需要在存储端进行大量的计算，因此选择了Node.js作为存储端实现方式，Node.js的特点使得其十分适合处理IO密集型任务而不擅长于CPU密集型任务。  
除了语言本身的特点之外，Node.js还提供了一个默认的包管理器npm，开发者可以利用npm将自己编写好的模块上传至官方仓库，也可以利用npm下载其它人的模块。在2019年6月初，官方仓库中的模块总量就突破了一百万，足以证明Node.js社区的活跃，在npm的帮助下Node.js的开发效率也相当不错。

### 2.3 Express
Node.js下的Web框架有很多，如Express，Koa，NestJS等，每个框架都有自己的独特之处，从其中选取用于存储端的Web框架之前，要明确存储端在整个监控系统中扮演的具体角色。  
在本系统中，存储端需要承担的任务有：接收WebSocket连接中采集端上报的数据，将收到的数据写入数据库，提供查询数据的HTTP API用于前端可视化，接入监控告警模块。众多监控采集端在运行过程中会持续不停地向存储端上报数据，相当于存储端不是仅会在特定的某段时间内遇到流量高峰，而是始终运行在较高的流量压力之下，因此对Web框架的性能有一定的要求。其次，存储端对外服务方式为WebSocket和HTTP API，不需要像传统的Web应用那样还需要提供具体页面，所以用不到视图层或HTML模板一类的内容。  
Express是Node.js下的一个老牌Web框架，主打快速灵活和极简主义，它的历史最为悠久，使用人数也最多，利用社区提供的丰富中间件可以方便地进行定制和扩展。Koa是另一个主打轻量的框架，其开发者主要来自于Express，开发过程中追求最新的JavaScript语言特性，它比Express更小，性能也更高，默认不提供任何中间件，基本的路由功能也需要额外引入。NestJS相比前两者显得更为全面，它基于Express，使用微软的TypeScript编写，提供了TypeORM对象关系映射器，拥有类似于Java注解的装饰器。  
考虑到存储端的性能要求，NestJS被首先排除，它在各方面所做的优化使得它更符合传统Web框架的定义，适合用来编写大型的完整Web应用，但也因此损耗了Node.js的部分性能，不适合更加具体化的单一场景。Koa和Express相比显得过于简洁了，像是为那些优化已有程序并且追求极致的开发者准备的，完全由开发者自己进行定制。因此存储端的Web框架最终选择了Express，简洁灵活的同时又提供了Web开发的基础工具，社区规模庞大，和其它工具库的协作也较为方便。

### 2.4 React
前端三大框架分别为Angular，React和Vue。Angular作为其中最为完备的框架，学习曲线也最为陡峭，专注于大规模的复杂应用，灵活度受限。React是一套构建UI的框架，操作只集中在视图层，它可以与已知的各类前端库很好地配合，灵活度比Angular更高。Vue则是三者中最为灵活的一个，开发门槛低，易于理解和学习。  
本系统中设计的前端和后端是完全解耦的，单纯通过HTTP API进行通信，因此不需要用到Angular这种大而全的框架，React或Vue即可满足全部需求。相比Vue来说React更加成熟，社区也更加庞大，因此最终选择了React来构建前端页面。  
React作为前端框架提供的是编写UI的方法，并没有现成的UI组件可以立即使用，所以实际开发中还需要搭配合适的UI库。Material-UI是GitHub上最受欢迎的React UI库之一，它不仅符合Google的Material Design规范，还提供有Material Design之外的实用组件，其完善的开发文档和丰富的代码示例十分适合入门学习，于是界面所用的UI库就选定了Material-UI。监控数据可视化部分需要用到大量的图表，React框架下最热门的图表库是Recharts，但在调研过程中发现它只适合用来做静态内容的展现，对于图表的刷新或者动态增加新数据的处理比较困难，因此换用了对动态图表更加友好的Chart.js，虽然其属于通用的JavaScript库，但得益于React的灵活性，可以使用原生JavaScript进行一系列的封装，绕过React直接调用Chart.js操作图表数据，再封装成React组件后就不会影响到前端应用的其他部分。

### 2.5 TimescaleDB
对于持续增长的海量监控数据，传统的关系型数据库显得力所不逮，而专门的时序数据库则恰好适用于类似场景：与时间有关的数据大量写入，已写入的数据不需要修改，查询多为区间内数据统计。时序数据库会对在数据的压缩存储、聚合查询等多个方面进行针对性的优化。  
在DB-Engines的排行榜上，比较靠前的开源时序数据库有InfluxDB，OpenTSDB，TimescaleDB等。InfluxDB在时序数据库排行榜上稳居第一，它由Golang编写，目标是提供高性能的写入和查询，部署时无需任何外部依赖，但其开源版本只支持单机实例，集群部署属于商业版的高级功能。OpenTSDB基于HBase，依托于Hadoop生态系统下的HDFS进行存储，因此在巨量数据所必需的分布式架构下具有绝对优势，但仅仅用来存储各项系统资源占用的话未免有点大材小用了。而且使用OpenTSDB还需要依次配置Hadoop，ZooKeeper，Hbase，最后才是OpenTSDB的部署，引入OpenTSDB将极大地增加整个系统的复杂度，因此不再考虑。最后是TimescaleDB，它基于PostgreSQL数据库，在时序数据的快速存储和复杂查询上进行了优化，并扩充了PostgreSQL的函数库，例如加入了histogram()计算直方图，lsof()向前查找最新的数据，time_bucket()按时间段聚合数据等。其最大的优点是继承了PostgreSQL的完整SQL支持，可以利用PostgreSQL生态下的现有工具。相比之下，InfluxDB由于使用Golang从头编写，就需要自己实现数据库相关的容错机制，如主从复制，高可用性，备份等，继承自PostgreSQL的TimescaleDB明显在可靠性上占有优势。除此之外，TimescaleDB官方提供了多个版本的Docker镜像，开发或部署时都可以轻松的构建所需环境。

### 2.6 本章小结
技术选型在毕业设计的准备阶段极为重要，没有任何一门技术可以完美地适用于所有开发场景，必须要根据实际需要选取最为合适的解决方案，技术选型将直接影响到接下来的系统设计以及系统实现。本章主要对技术选型最终确定的关键技术进行了简要的论述，明确了所选技术的主要优势以及选择的原因，在后文的系统设计和系统实现部分均会体现出该技术选型所带来的长远影响。

## 3. 需求分析

### 3.1 系统概述
本系统的目标是设计并实现一套用于Linux服务器的监控告警系统，其主要任务包括：服务器正常运行时可以查看历史监控数据，为应用程序的分析优化提供依据；服务器出现异常情况时及时推送告警信息，协助开发人员定位问题。  
根据主要任务来对系统需求进行整体分析，查看历史监控数据要求监控数据必须具备完整的采集、传输、存储流程，并且提供历史数据的查询接口，能够以可视化图表的形式展示历史监控数据，便于开发人员根据历史数据分析资源指标变化趋势，在时间维度上纵向分析服务器状态；异常发生时的及时告警要求此系统可以对各个监控指标设定阈值，对采集到的监控数据进行分析判断，当监控数据达到阈值或满足指定的报警条件后，触发告警机制，根据提前设定好的信息推送渠道将告警信息发送至接收者，同时明确触发告警的服务器及监控规则，方便及时定位服务器故障详细位置，此外监控系统还要允许在故障排除后将异常服务器状况标记为已修复，防止已被处理的过期告警引起混乱。  
对于用户来说，运维人员在相应的服务器上部署完对应的模块后，即可在核心控制台上查看加入到监控系统中的各服务器状态，可以根据服务器运行的历史状态调整指定资源的报警阈值，并添加多种推送渠道用于接收告警信息。

### 3.2 功能性需求分析

#### 3.2.1 数据采集
数据采集模块是监控告警系统的基础，它需要通过Linux系统调用、访问/proc伪文件系统等方式获取Linux系统的资源占用与性能信息，然后将采集到的数据进行预处理，再封装成数据包通过WebSocket发送给存储模块。  
参考国内著名云服务商阿里云所提供的云监控说明文档，数据采集模块从被监控服务器上获取的监控项至少要包含以下几项：基础信息（发行版，内核版本，主机名，CPU型号，CPU核心数），CPU使用率，内存使用情况，交换空间使用情况，系统1/5/15分钟内平均负载，网络流量在单位时间内的上传与下载情况，系统磁盘在单位时间内的读取与写入情况，系统挂载点统计（设备名称，挂载点位置，文件系统，总容量，已用容量，总Inode数量，已用Inode数量）。除此之外，为增强Linux服务器的安全性，数据采集模块还可以监听SSH远程登录事件，指定文件的修改删除事件。  
数据采集模块在部署后将自动运行，无需参与者，其数据流如图3-1。

图3-1 数据采集模块数据流图

#### 3.2.2 数据存储
数据存储模块需要对监控告警系统采集到的各项指标进行存储，判断存储方案是否合适需要考虑写入速度，空间占用，数据安全，查询速度等多个方面。由于数据存储模块所存储的监控数据具有明显的特征，如随时间变化，持续不断增长等，所以可以采用更具有针对性的时序数据库来进行存储。  
时序数据库普遍性地优化了大批量数据的并行插入，并对时间维度下的数据使用更为高效的压缩算法进行存储，减小磁盘空间占用，在查询方面也会优化大量数据下常用的一些聚合函数，可以为系统中的数据可视化提供方便。数据安全方面则得益于TimescaleDB继承的PostgreSQL生态，可以使用流式复制保证数据库的高可用性，主库出现异常情况宕机时从机可以快速切换，防止单个数据库的宕机影响到整个监控系统。PostgreSQL也提供了完善的物理和逻辑备份工具，该工具可以完美用于TimescaleDB，进一步确保数据的安全性。  
数据存储模块在整个系统中承担桥梁的作用，联系着各个模块。它需要为数据采集模块提供初始化注册功能，接收来自已注册数据采集模块的数据；它需要连接数据库，将校验后的合法数据存入数据库；它还连接着监控报警模块，存储管理员设定的报警规则，并将数据采集模块上报的数据推送给监控报警模块进行检查；最后它还要为可视化模块提供数据来源，根据需要的图表类型进行适当的查询优化。  
数据存储模块在部署后同样自动运行，仅与其它各个模块直接发生数据传输，无需具体参与者，其数据流如图3-2。

图3-2 数据存储模块数据流图

#### 3.2.3 监控报警
监控报警算是一个相对比较独立的模块，其主要任务是分析数据存储模块发送过来的数据，当检测到对应的报警规则被触发后，根据设定的推送渠道发送告警信息。这部分就不仅仅是模块之间的内部合作了，还需要管理员的参与。  
监控报警模块首先需要确定监控规则的结构，针对数据采集端收集到的各项监控数据设定的各类规则都要符合或者转化成统一的结构之后才能利用关系型数据库进行存储。作为监控规则，首先需要有明确的监控目标，例如CPU，内存，负载等，有了目标之后需要指定明确的事件，例如使用率达到阈值，速度达到阈值等，接下来指定阈值。为了减少监控数据的偶然峰值造成的误告警，监控规则还可以指定数据聚合区间，例如CPU在过去的五分钟内持续达到阈值才触发告警，而不是单次监控数据达到阈值。触发告警后对应的监控规则还应有可设定的静默时间，防止告警后不断重复告警形成的信息轰炸。  
告警模块应当支持当前常用的通知方式，例如电子邮件，短信，常用的办公IM（企业微信，钉钉，飞书等），管理员可以添加推送渠道后按需设定监控规则的接收者。  
监控报警模块的主要需求不再是数据在不同部分的流动了，而是涉及到了管理员的各项操作，需要提供每种操作对应的后端API，其用例图如图3-3。

图3-3 监控报警模块用例图

#### 3.2.4 可视化
可视化模块是直接与管理员交互的模块，一方面需要负责监控数据的查看，在服务器正常运行时显示历史数据供管理员分析系统瓶颈，预测可能出现的威胁，在服务器异常时明确引发报警的数据，帮助管理员快速定位问题；另一方面需要提供系统功能的控制界面，管理员应当在可视化模块的控制界面上进行相关操作，如查看已注册的主机列表，管理报警规则，管理推送渠道等。  
对于历史数据的查看，应当提供不同的区间设置或者允许管理员自定义区间进行查看，这样管理员既可以缩小区间查看某一小段时间内的详细监控数据，又可以增大区间查看较大时间范围内的数据变化趋势。可视化模块中也可增加独立的概览页面，显示监控系统内整体主机运行状况统计，并提供常用的功能入口，如显示最近查看过的主机，最近修改过的监控规则。  
可视化模块需要提供管理员操作的直接交互接口，其用例图如图3-4。

图3-3 可视化模块用例图

### 3.3 非功能性需求分析

#### 3.3.1 可行性分析
本监控告警系统主要针对Linux服务器，Linux系统是一类开放的操作系统，对开发者极为友好，例如man手册中包含了所有的Linux内核相关系统调用，还介绍了/proc伪文件系统中的文件含义及内容格式，常用的系统资源查看命令如top，free，ps，htop等均提供了开源代码，因此在监控数据采集上不存在无法解决的难题，具有程序可行性，还可以参考常用监控命令的计算方式计算出更符合运维人员直觉的监控指标。  
数据存储模块有时序数据库TimescaleDB提供底层存储支持，其背后是拥有二十多年历史的PostgreSQL，庞大的社区保证了在学习，开发，部署的完整过程中都有足够的资料进行查询，对于常见的各种问题都已经有了相应的解决方案，因此数据存储模块的设计与实现也是切实可行的。  
监控报警主要是接入各种消息推送渠道，常见的邮件发送方案是SMTP协议，配合自己的域名邮箱可以轻松发送告警邮件，只需要注意免费的邮箱通常有每日发送数量限制，生产环境下应当接入自建的企业邮箱或使用邮件相关的付费服务。常用的办公IM如企业微信，钉钉，飞书等，均提供了在企业群组中添加通知机器人的功能，查看相关文档后发现都是类似的Webhook接口，在编程过程中可以轻松调用。对于更加实时的短信推送，查看相关服务后发现均需企业认证，以个人身份申请需要较长审核流程，而且无免费服务，因此本地开发时只能使用kde-connect直接连接手机模拟通过程序进行短信告警。  
可视化模块选用的是流行的React前端框架，搭配组件丰富的Material-UI前端库，足够实现该系统所需的各类交互，为操作者提供良好的操作体验。图表方面Chart.js官方对于各类图表都提供了具体的代码示例，并且文档中也结合常用场景介绍了相关优化，GitHub的issue页面可以查找到开发过程中的常见问题，因此可视化模块方面也不存在明显困难。

#### 3.3.2 性能效率分析
考虑到监控系统需要处理持续不断的新增数据，技术选型时就选择了具有一定性能优势的技术。例如监控数据采集端选用Golang进行编写，原生支持并发使得并行采集各项监控数据十分简单，采集到的数据后续的处理也可以与采集过程并行处理，采集端能够提供极细粒度下的监控数据。采集到的监控数据通过WebSocket长连接进行发送，相比普通的HTTP连接减小了重复建立连接的消耗，不需要每次都发送Header或是进行身份验证，提高了数据传输效率，除此之外也可以利用WebSocket长连接的特点监控目标主机的连接与断开，避免了轮询方式带来的性能损耗。数据存储端选用的是Node.js，其事件驱动和非阻塞异步I/O有效地提升了对于大量并发连接的承载能力，对于当前这种非计算密集型应用十分高效。可视化模块中的系统功能控制界面展示数据量有限，不会遇到性能方面的问题，但历史监控数据展示界面的Chart.js图表将会处理大量数据，例如管理员查看近一个月内的监控数据来分析整体趋势，每10秒上报一次的监控采集端将会累计达到二十五万个数据点，前端无法直接处理如此多的数据，后端发送这么多数据的代价也是极大的，因此后端需要对数据进行聚合，此处正好用到了时序数据库TimescaleDB提供的聚合函数，可以根据总的时间范围计算出合适的聚合区间，然后按聚合区间将数据进行压缩，减少数据点数量同时不影响整体趋势。

#### 3.3.3 安全性分析
本系统分为多个模块，其中模块之间需要相互通信，部分模块还需要连接外网，必须要严格考虑系统整体的对外安全性。  
数据采集模块不需要连接外网，只需要连接存储模块进行监控数据上报，因此考虑安全性的地方是WebSocket连接的认证。Linux系统本身提供有machine-id，采集模块首次启动时发送machine-id到存储模块请求注册，存储模块使用AES-256-CFB进行加密，其中key在存储模块中提前配置，iv使用Node.js随机生成，加密后的结果作为token返回给采集模块，同时插入数据库。此后WebSocket握手过程中需要指明token用于身份认证。使用加密而不是哈希是为了能够逆向计算出原machine-id，允许数据采集模块主动刷新token，对旧的token进行失效处理，AES-256-CFB则可以保证每次刷新都可以生成不同的token。  
存储模块除了接收数据采集模块上报的监控数据外，还需要为可视化模块提供查询功能，因此实现了一个简单的登录注册，登录后才可以访问到可视化模块，存储模块的各个查询接口都需要校验用户登录状态。用户的密码在数据库中与邮箱共同哈希后进行存储，哈希可以有效防止数据库泄露后一同泄露用户密码，与邮箱共同哈希则大大增加了哈希碰撞的难度。用户的登录状态使用服务端session进行存储，技术选型中选择的Express提供了成熟的redis-session中间件，redis统一管理session可以为存储端的多机部署提前打下基础。  
除具体模块外，数据库相关的安全设置则推荐设置数据库为内网监听，仅允许存储模块通过内网IP进行访问，不对外暴露端口。

### 3.4 本章小结
需求分析是毕业设计前期一个极为重要的步骤，本章的系统概述章节介绍了Linux服务器监控告警系统的整体需求，功能性需求分析则对系统的各个模块进行梳理，结合实际监控场景明确该系统要实现的功能，同时保留适当的扩展性，非功能性需求分析分别从可行性、性能效率、安全性几个方面结合已划分的几个模块进行论述，分析了需要在各个方面的优化上做出的努力。

## 4. 系统设计

### 4.1 设计目标
### 4.2 系统总体功能架构
### 4.3 系统技术实现架构
### 4.4 数据存储及使用
### 4.5 本章小结

## 5. 系统实现

### 5.1 数据采集模块
### 5.2 数据存储模块
### 5.3 前端可视化模块
### 5.4 本章小结

## 6. 系统测试

## 7. 总结

## 致谢